{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/en_infoboxes.pickle', 'rb') as f:\n",
    "    en_infoboxes = pickle.load(f)\n",
    "\n",
    "with open('data/nl_infoboxes.pickle', 'rb') as f:\n",
    "    nl_infoboxes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_infoboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "clean = {\n",
    "    '[': ' ',\n",
    "    ']': ' ',\n",
    "    '{': ' ',\n",
    "    '}': ' ',\n",
    "    '|': ' ',\n",
    "}\n",
    "\n",
    "translation = str.maketrans(clean)\n",
    "WHITESPACE_PATTERN = re.compile(r'\\W+')\n",
    "TAG_PATTERN = re.compile(r'<[^>]+>')\n",
    "\n",
    "def clean_str(string):\n",
    "    # remove brackets\n",
    "    string = string.translate(translation)\n",
    "    # remove html tags\n",
    "    string = re.sub(TAG_PATTERN, ' ', string)\n",
    "    # Collapse whitespace\n",
    "    string = re.sub(WHITESPACE_PATTERN, ' ', string)\n",
    "    return string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_iterables(item):\n",
    "    if (type(item) in (int, float)):\n",
    "        return item\n",
    "    elif type(item) == str:\n",
    "        return clean_str(item)\n",
    "    elif len(item) > 0 and all(type(a) not in (list, tuple, set) for a in item):\n",
    "        return item\n",
    "    \n",
    "    return unpack_iterables(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in en_infoboxes.items():\n",
    "    if type(v) == dict:\n",
    "        for k1, v1 in v.items():\n",
    "            en_infoboxes[k][k1] = unpack_iterables(v1)\n",
    "en_infoboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nl_infoboxes.copy()\n",
    "for k, v in tmp.items():\n",
    "    if not v:\n",
    "        nl_infoboxes.pop(k)\n",
    "    elif type(v) == dict:\n",
    "        for k1, v1 in v.items():\n",
    "            nl_infoboxes[k][k1] = unpack_iterables(v1)\n",
    "nl_infoboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/nl_infoboxes_clean.pickle', 'wb') as f:\n",
    "    pickle.dump(nl_infoboxes, f)\n",
    "\n",
    "with open('data/en_infoboxes_clean.pickle', 'wb') as f:\n",
    "    pickle.dump(en_infoboxes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_available = en_infoboxes.keys() & nl_infoboxes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in nl_infoboxes.items():\n",
    "    for k1, v1 in v.items():\n",
    "        if '[' in v:\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(en_infoboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(both_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a set so we only keep track of unique mappings\n",
    "matches = {\n",
    "    'exact_key': set(),\n",
    "    'full_match': set(),\n",
    "    'partial_match': set(),\n",
    "}\n",
    "\n",
    "for key in both_available:\n",
    "    for nl_k, nl_v in nl_infoboxes[key].items():\n",
    "        for en_k, en_v in en_infoboxes[key].items():\n",
    "            nl_k = nl_k.lower()\n",
    "            en_k = en_k.lower()\n",
    "            result = (en_k, nl_k)\n",
    "\n",
    "            # TODO hier keys groeperen die dezelfde waarden hebben\n",
    "            # zodat [isbn, issn] samenkomen of\n",
    "            # [uitgeverij, originele uitgever, uitgever]\n",
    "            # beide kanten op kijken of je al bestaande keys hebt voor het nl en\n",
    "            # en\n",
    "\n",
    "            if nl_k == en_k:\n",
    "                matches['exact_key'].add(result)\n",
    "            elif nl_v == en_v:\n",
    "                matches['full_match'].add(result)\n",
    "            elif (nl_v in en_v) or (en_v in nl_v):\n",
    "                matches['partial_match'].add(result)\n",
    "\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_boxes, left_untouched_boxes = [], []\n",
    "for title, existing_infobox in en_infoboxes.items():\n",
    "    # we have an existing infobox for Dutch, check if we need to expand it\n",
    "    if title in nl_infoboxes.keys():\n",
    "        nl_existing = nl_infoboxes[title]\n",
    "        nl_new = nl_existing.copy()\n",
    "        for nl_k, nl_v in nl_existing.items():\n",
    "            en_existing = en_infoboxes[title]\n",
    "            for en_k, en_v in en_existing.items():\n",
    "                if en_v == nl_v:\n",
    "                    continue\n",
    "\n",
    "                # TODO: Dit is niet best, we kunnen beter de keys waarvan we weten\n",
    "                # dat ze bestaan in de Engelse infobox verzamelen en die \n",
    "                # toepassen, maar met sets van tuples is dat niet handig\n",
    "                # for k in matches.keys():\n",
    "                for k in ['exact_key', 'full_match']:\n",
    "                    reason = f'Door {k}'\n",
    "                    for en_map, nl_map in matches[k]:\n",
    "                        if en_map == en_k and nl_map not in nl_new and en_v not in nl_new.values():\n",
    "                            nl_new[nl_map] = (en_existing[en_map], reason)\n",
    "        if nl_new != nl_existing:\n",
    "            expanded_boxes.append({'old': nl_existing, 'new': nl_new})\n",
    "        else:\n",
    "            left_untouched_boxes.append(nl_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(expanded_boxes), len(left_untouched_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in expanded_boxes:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = []\n",
    "# with open('data/titlesAE.txt') as f:\n",
    "#     total.extend(f.readlines())\n",
    "\n",
    "# with open('data/titlesFZ.txt') as f:\n",
    "#     total.extend(f.readlines())\n",
    "\n",
    "# with open('data/sf_fantasy_light_mostpop.txt') as f:\n",
    "#     total.extend(f.readlines())\n",
    "\n",
    "# total = sorted(list(set(total)))\n",
    "\n",
    "# with open('titles.txt', 'w') as f:\n",
    "#     f.write(''.join(total))\n",
    "\n",
    "# # Handmatig checken op:\n",
    "# #   - wikipediadump xml blabla\n",
    "# #   - Dingen die bovenaan staan (punct marks etc.)\n",
    "# #   - &amp; vervangen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from extract_mappings import Mapping, Mapper\n",
    "\n",
    "\n",
    "with open('data/mappings.pickle', 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "with open('data/mapper.pickle', 'rb') as f:\n",
    "    mapper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(mappings).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping(en_key='name', nl_key='ja_naam_trans', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='genre', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='Huidige', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='tv_com', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='tagline', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='reeks', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='volgendeboek', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='cover-op-enwp', train_count=24, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='afbeelding', train_count=21, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='poster-op-enwp', train_count=4, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='name', nl_key='uitgever', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='genre', nl_key='extra portaal', train_count=63, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='film', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='uitgever', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='titel', train_count=10, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='nextevent2', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='volledigenaam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='naam', train_count=13, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='orig titel', train_count=50, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image', nl_key='poster-op-enwp', train_count=22, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='pages', nl_key='uitgiftedatum', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='publisher', nl_key='auteur', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='publisher', nl_key='naam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='illustrator', nl_key='illustraties', train_count=22, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='wikisource', nl_key='afbeelding', train_count=7, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='wikisource', nl_key='uitgever', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='release_date', nl_key='paginas', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='series', nl_key='naam', train_count=3, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='runtime', nl_key='lengte', train_count=31, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='runtime', nl_key='speelduur', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='runtime', nl_key='duur', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='preceded_by', nl_key='orig titel', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='preceded_by', nl_key='voorloper', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='followed_by', nl_key='naam', train_count=3, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='followed_by', nl_key='volgendeboek', train_count=9, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='followed_by', nl_key='vervolg', train_count=33, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='followed_by', nl_key='orig titel', train_count=3, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='published', nl_key='originele uitgever', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='published', nl_key='uitgever', train_count=3, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='published', nl_key='uitgiftedatum origineel', train_count=4, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='published', nl_key='uitgiftedatum', train_count=3, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='media_type', nl_key='medium', train_count=16, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='title_orig', nl_key='afbeelding', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='title_orig', nl_key='orig titel', train_count=35, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='parents', nl_key='ouders', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='alt', nl_key='orig titel', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='alt', nl_key='volledige naam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='alt', nl_key='afbeelding', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='developer', nl_key='bedenker', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='starring', nl_key='spelers', train_count=13, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='country', nl_key='land', train_count=12, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='country', nl_key='taal', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='country', nl_key='extra portaal', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='caption', nl_key='onderschrift', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='caption', nl_key='volledige naam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='caption', nl_key='naam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='caption', nl_key='orig titel', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='birth_name', nl_key='naam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='language', nl_key='originele taal', train_count=4, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='language', nl_key='taal', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='type_species_authority', nl_key='auteur', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image_caption', nl_key='onderschrift', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='released', nl_key='premi√®re', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='based_on', nl_key='bronmateriaal', train_count=3, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='birth_place', nl_key='geboorteplaats', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='image_size', nl_key='afbeeldingbreedte', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='label', nl_key='naam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='label', nl_key='orig titel', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='nationality', nl_key='nationaliteit', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='nationality', nl_key='gemeenschap', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='native_name', nl_key='afbeelding', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='birth_date', nl_key='geboortedatum', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='full name', nl_key='geboortenaam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='alias', nl_key='titel', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='authors', nl_key='auteur', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='father', nl_key='geboortenaam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='regnal name', nl_key='keizernaam', train_count=2, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='regnal name', nl_key='adoptief zoon', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='first', nl_key='eerste', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='alternative title(s)', nl_key='naam', train_count=1, reason='Normalized value Levenshtein match')\n",
      "Mapping(en_key='origin', nl_key='oorsprong', train_count=1, reason='Normalized value Levenshtein match')\n"
     ]
    }
   ],
   "source": [
    "for k, v in mapper.map.items():\n",
    "    for m in v:\n",
    "        if m.reason == 'Normalized value Levenshtein match':\n",
    "            print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Mapping(en_key='publisher', nl_key='uitgever', train_count=60, reason='Exact value match'),\n",
       " Mapping(en_key='publisher', nl_key='originele uitgever', train_count=53, reason='Exact value match'),\n",
       " Mapping(en_key='publisher', nl_key='auteur', train_count=1, reason='Normalized value Levenshtein match'),\n",
       " Mapping(en_key='publisher', nl_key='naam', train_count=1, reason='Normalized value Levenshtein match'),\n",
       " Mapping(en_key='publisher', nl_key='uitgeverij', train_count=1, reason='Exact value match')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.get_mappings('publisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len({m.en_key for m in mappings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.get_mappings('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "en_infoboxes = load_pickle('data/train/en_infoboxes_clean.pickle')\n",
    "nl_infoboxes = load_pickle('data/train/nl_infoboxes_clean.pickle')\n",
    "\n",
    "both_available = en_infoboxes.keys() & nl_infoboxes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(x):\n",
    "    return sum(x) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.066856330014225, 13.84068278805121)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_key_counts = []\n",
    "nl_key_counts = []\n",
    "\n",
    "for k in both_available:\n",
    "    en_key_counts.append(len(en_infoboxes[k]))\n",
    "    nl_key_counts.append(len(nl_infoboxes[k]))\n",
    "\n",
    "avg(en_key_counts), avg(nl_key_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg len infoboxes train set\n",
    "# en: 14,1\n",
    "# nl: 13,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.525 4.0 3.375 14.65\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    301 / 40,\n",
    "    160 / 40,\n",
    "    135 / 40,\n",
    "    586 / 40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set results\n",
    "# total_correct_exact_k: 301\n",
    "# total_correct_exact_v: 160\n",
    "# total_correct_exact_pairs: 135\n",
    "# total_pairs_generated: 586        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average correct keys per infobox: 7.525 \n",
    "# average correct values per infobox: 4.0 \n",
    "# average correct pairs per infobox: 3.375 \n",
    "# average total pairs generated per infobox: 14.65"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47fbbe73ee95fc20997b9f9092b84106529efe2515f3dda90cfda1de4a78362a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
